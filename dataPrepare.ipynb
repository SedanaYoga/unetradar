{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.5.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python35464bit4a11378904884981aa53a5ff31f05237",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentasi\n",
    "\n",
    "Pembuatan data augmentasi menggunakan library **keras.preprocessing.image.ImageDataGenerator** yang bisa menggabungkan Deep Neural Network image dan label secara bersamaan."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tentukan parameter data generator\n",
    "Gunakan parameter dengan metode random dictionary seperti dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict()#rotation_range = 0.1,\n",
    "                    #width_shift_range = 0.01,\n",
    "                    #height_shift_range = 0.01,\n",
    "                    #shear_range = 0.05,\n",
    "                    #zoom_range = 0.1,\n",
    "                    #horizontal_flip = True,\n",
    "                    #fill_mode = 'nearest')\n",
    "myGenerator = trainGenerator(30, 'data/train', 'image', 'label', data_gen_args, save_to_dir = \"data/train/aug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Membuat data augmentasi ke folder **'data/train/aug/'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n"
    }
   ],
   "source": [
    "num_batch = 20\n",
    "for i, batch in enumerate(myGenerator):\n",
    "    print(i)\n",
    "    if(i>=(num_batch-1)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Membuat .npy data (data augmentasi yang sudah dikompres)\n",
    "Butuh memori tambahan untuk menyimpan data ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr,mask_arr = geneTrainNpy(\"data/train/aug/\",\"data/train/aug/\")\n",
    "np.save(\"data/image_arr.npy\",image_arr)\n",
    "np.save(\"data/mask_arr.npy\",mask_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "red = np.array([255, 0, 0])\n",
    "green = np.array([0, 255, 0])\n",
    "blue = np.array([0, 0, 255])\n",
    "yellow = np.array([255, 255, 0])\n",
    "aqua = np.array([0, 255, 255])\n",
    "\n",
    "def masking(img, mask, color = None):\n",
    "    mask_out = np.zeros((432, 532, 3), dtype = 'uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) # kalau shapenya (432,532) atau grayscale\n",
    "    for i in range(mask.shape[0]-1):\n",
    "        for j in range(mask.shape[1]-1):\n",
    "            if (mask[i,j] >= 220):\n",
    "                mask_out[i,j,:] = mask[i,j] \n",
    "                mask_out[i,j,:] = color\n",
    "                img[i,j,:] = mask_out[i,j,:]\n",
    "    segmented = img\n",
    "    return segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Creating... data/test/231_predict.png\nCreating... data/test/232_predict.png\nCreating... data/test/233_predict.png\nCreating... data/test/234_predict.png\nCreating... data/test/235_predict.png\nCreating... data/test/236_predict.png\nCreating... data/test/237_predict.png\n"
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "from IPython.display import clear_output\n",
    "\n",
    "results_path = 'data/test/'\n",
    "results_results = 'results/'\n",
    "list_file = os.listdir(results_path)\n",
    "#real = np.zeros((len(list_file)//2, 432, 532), dtype ='uint8')\n",
    "masked = np.zeros((len(list_file)//2, 432, 532, 3), dtype ='uint8')\n",
    "\n",
    "for i in range(len(list_file)//2):\n",
    "    masked[i] = masking(io.imread(results_path+str(i)+'.png'), io.imread(results_path+str(i)+'_predict.png'), yellow)\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        clear_output(wait=True)\n",
    "    else:\n",
    "        print('Creating... ' + results_path+str(i)+'_predict.png')\n",
    "\n",
    "    io.imsave(os.path.join(results_results,\"%d.png\"%i), masked[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARA CONVERT PNG TO MP4\n",
    "## ffmpeg -r 30 -f image2 -i %d.png -vcodec libx264 -crf 15  -pix_fmt yuv420p test.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARA MENGGABUNGKAN 2 VIDEO YANG SAMA\n",
    "## ffmpeg -i Yoga60.avi -i aqua.mp4 -filter_complex \"[0:v]pad=iw*2:ih[int]; [int][1:v]overlay=W/2:0[vid]\" -map \"[vid]\" -c:v libx264 -crf 15 output2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}